{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_Implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a42c61f133e34f3787a6b0fac9a484ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_026bc4bae71c45e38d4858049f07b4ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a035fd6af3fc41e098ec844abe72a3ab",
              "IPY_MODEL_2f5d99a58b0c44c884506304b8154f54"
            ]
          }
        },
        "026bc4bae71c45e38d4858049f07b4ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a035fd6af3fc41e098ec844abe72a3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c5d9ee99c66d4e23abf6008b2dd73fd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1539d9ecd6154daab03c83a20d1d6a16"
          }
        },
        "2f5d99a58b0c44c884506304b8154f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b5dbd830387345868203978de59c0440",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 32741641.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c753652c73d641a1acc2304a13458739"
          }
        },
        "c5d9ee99c66d4e23abf6008b2dd73fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1539d9ecd6154daab03c83a20d1d6a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5dbd830387345868203978de59c0440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c753652c73d641a1acc2304a13458739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixq6pq7dMwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vC68vOFdZZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "587e4476-4080-46f5-d3a8-d7f4d2d36527"
      },
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', DEVICE)\n",
        "\n",
        "# Hyperparameters\n",
        "random_seed = 1\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "# Architecture\n",
        "num_features = 784\n",
        "num_classes = 10"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNCWg5T4ddnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "a42c61f133e34f3787a6b0fac9a484ab",
            "026bc4bae71c45e38d4858049f07b4ea",
            "a035fd6af3fc41e098ec844abe72a3ab",
            "2f5d99a58b0c44c884506304b8154f54",
            "c5d9ee99c66d4e23abf6008b2dd73fd4",
            "1539d9ecd6154daab03c83a20d1d6a16",
            "b5dbd830387345868203978de59c0440",
            "c753652c73d641a1acc2304a13458739"
          ]
        },
        "outputId": "e91b5443-4c25-4584-8544-b16c01d784d8"
      },
      "source": [
        "\n",
        "##########################\n",
        "### MNIST DATASET\n",
        "##########################\n",
        "\n",
        "# Note transforms.ToTensor() scales input images\n",
        "# to 0-1 range\n",
        "train_dataset = datasets.CIFAR10(root='data', \n",
        "                                 train=True, \n",
        "                                 transform=transforms.ToTensor(),\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=False, \n",
        "                                transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=batch_size, \n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=batch_size, \n",
        "                         shuffle=False)\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a42c61f133e34f3787a6b0fac9a484ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Image batch dimensions: torch.Size([128, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfkc6iWNdkWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################\n",
        "### MODEL\n",
        "##########################\n",
        "\n",
        "\n",
        "class VGG16(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(VGG16, self).__init__()\n",
        "        \n",
        "        # calculate same padding:\n",
        "        # (w - k + 2*p)/s + 1 = o\n",
        "        # => p = (s(o-1) - w + k)/2\n",
        "        \n",
        "        self.block_1 = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=3,\n",
        "                          out_channels=64,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          # (1(32-1)- 32 + 3)/2 = 1\n",
        "                          padding=1), \n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=64,\n",
        "                          out_channels=64,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))\n",
        "        )\n",
        "        \n",
        "        self.block_2 = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=64,\n",
        "                          out_channels=128,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=128,\n",
        "                          out_channels=128,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))\n",
        "        )\n",
        "        \n",
        "        self.block_3 = nn.Sequential(        \n",
        "                nn.Conv2d(in_channels=128,\n",
        "                          out_channels=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=256,\n",
        "                          out_channels=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),        \n",
        "                nn.Conv2d(in_channels=256,\n",
        "                          out_channels=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))\n",
        "        )\n",
        "        \n",
        "          \n",
        "        self.block_4 = nn.Sequential(   \n",
        "                nn.Conv2d(in_channels=256,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),        \n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),        \n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),            \n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))\n",
        "        )\n",
        "        \n",
        "        self.block_5 = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),            \n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),            \n",
        "                nn.Conv2d(in_channels=512,\n",
        "                          out_channels=512,\n",
        "                          kernel_size=(3, 3),\n",
        "                          stride=(1, 1),\n",
        "                          padding=1),\n",
        "                nn.ReLU(),    \n",
        "                nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                             stride=(2, 2))             \n",
        "        )\n",
        "            \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(True),\n",
        "            #nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            #nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "            \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    m.bias.detach().zero_()\n",
        "                    \n",
        "        #self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_3(x)\n",
        "        x = self.block_4(x)\n",
        "        x = self.block_5(x)\n",
        "        #x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.classifier(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "\n",
        "        return logits, probas\n",
        "\n",
        "    \n",
        "torch.manual_seed(random_seed)\n",
        "model = VGG16(num_features=num_features,\n",
        "              num_classes=num_classes)\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWCdm54SdyEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d5d2841-052a-463f-94b9-346b149d0cd4"
      },
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "    model.eval()\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "            \n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "\n",
        "        logits, probas = model(features)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "\n",
        "\n",
        "def compute_epoch_loss(model, data_loader):\n",
        "    model.eval()\n",
        "    curr_loss, num_examples = 0., 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data_loader:\n",
        "            features = features.to(DEVICE)\n",
        "            targets = targets.to(DEVICE)\n",
        "            logits, probas = model(features)\n",
        "            loss = F.cross_entropy(logits, targets, reduction='sum')\n",
        "            num_examples += targets.size(0)\n",
        "            curr_loss += loss\n",
        "\n",
        "        curr_loss = curr_loss / num_examples\n",
        "        return curr_loss\n",
        "    \n",
        "    \n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "        \n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "            \n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        cost.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
        "                   %(epoch+1, num_epochs, batch_idx, \n",
        "                     len(train_loader), cost))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False): # save memory during inference\n",
        "        print('Epoch: %03d/%03d | Train: %.3f%% |  Loss: %.3f' % (\n",
        "              epoch+1, num_epochs, \n",
        "              compute_accuracy(model, train_loader),\n",
        "              compute_epoch_loss(model, train_loader)))\n",
        "\n",
        "\n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
        "    \n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/010 | Batch 0000/0391 | Cost: 2.4443\n",
            "Epoch: 001/010 | Batch 0050/0391 | Cost: 2.2965\n",
            "Epoch: 001/010 | Batch 0100/0391 | Cost: 2.2051\n",
            "Epoch: 001/010 | Batch 0150/0391 | Cost: 1.9724\n",
            "Epoch: 001/010 | Batch 0200/0391 | Cost: 1.9630\n",
            "Epoch: 001/010 | Batch 0250/0391 | Cost: 1.8367\n",
            "Epoch: 001/010 | Batch 0300/0391 | Cost: 1.8061\n",
            "Epoch: 001/010 | Batch 0350/0391 | Cost: 1.8978\n",
            "Epoch: 001/010 | Train: 26.872% |  Loss: 1.832\n",
            "Time elapsed: 0.79 min\n",
            "Epoch: 002/010 | Batch 0000/0391 | Cost: 1.7710\n",
            "Epoch: 002/010 | Batch 0050/0391 | Cost: 1.8244\n",
            "Epoch: 002/010 | Batch 0100/0391 | Cost: 1.7095\n",
            "Epoch: 002/010 | Batch 0150/0391 | Cost: 1.7233\n",
            "Epoch: 002/010 | Batch 0200/0391 | Cost: 1.3918\n",
            "Epoch: 002/010 | Batch 0250/0391 | Cost: 1.5310\n",
            "Epoch: 002/010 | Batch 0300/0391 | Cost: 1.5634\n",
            "Epoch: 002/010 | Batch 0350/0391 | Cost: 1.4418\n",
            "Epoch: 002/010 | Train: 45.218% |  Loss: 1.429\n",
            "Time elapsed: 1.60 min\n",
            "Epoch: 003/010 | Batch 0000/0391 | Cost: 1.4450\n",
            "Epoch: 003/010 | Batch 0050/0391 | Cost: 1.2522\n",
            "Epoch: 003/010 | Batch 0100/0391 | Cost: 1.3944\n",
            "Epoch: 003/010 | Batch 0150/0391 | Cost: 1.3155\n",
            "Epoch: 003/010 | Batch 0200/0391 | Cost: 1.3476\n",
            "Epoch: 003/010 | Batch 0250/0391 | Cost: 1.1843\n",
            "Epoch: 003/010 | Batch 0300/0391 | Cost: 1.2846\n",
            "Epoch: 003/010 | Batch 0350/0391 | Cost: 1.1534\n",
            "Epoch: 003/010 | Train: 61.374% |  Loss: 1.075\n",
            "Time elapsed: 2.43 min\n",
            "Epoch: 004/010 | Batch 0000/0391 | Cost: 0.9727\n",
            "Epoch: 004/010 | Batch 0050/0391 | Cost: 1.0923\n",
            "Epoch: 004/010 | Batch 0100/0391 | Cost: 1.1083\n",
            "Epoch: 004/010 | Batch 0150/0391 | Cost: 1.1303\n",
            "Epoch: 004/010 | Batch 0200/0391 | Cost: 1.0323\n",
            "Epoch: 004/010 | Batch 0250/0391 | Cost: 1.0466\n",
            "Epoch: 004/010 | Batch 0300/0391 | Cost: 1.0617\n",
            "Epoch: 004/010 | Batch 0350/0391 | Cost: 1.0389\n",
            "Epoch: 004/010 | Train: 68.628% |  Loss: 0.905\n",
            "Time elapsed: 3.27 min\n",
            "Epoch: 005/010 | Batch 0000/0391 | Cost: 0.8782\n",
            "Epoch: 005/010 | Batch 0050/0391 | Cost: 0.7104\n",
            "Epoch: 005/010 | Batch 0100/0391 | Cost: 0.8687\n",
            "Epoch: 005/010 | Batch 0150/0391 | Cost: 0.8901\n",
            "Epoch: 005/010 | Batch 0200/0391 | Cost: 0.9299\n",
            "Epoch: 005/010 | Batch 0250/0391 | Cost: 0.7038\n",
            "Epoch: 005/010 | Batch 0300/0391 | Cost: 0.7549\n",
            "Epoch: 005/010 | Batch 0350/0391 | Cost: 0.7990\n",
            "Epoch: 005/010 | Train: 73.658% |  Loss: 0.756\n",
            "Time elapsed: 4.11 min\n",
            "Epoch: 006/010 | Batch 0000/0391 | Cost: 0.6590\n",
            "Epoch: 006/010 | Batch 0050/0391 | Cost: 0.6477\n",
            "Epoch: 006/010 | Batch 0100/0391 | Cost: 0.7857\n",
            "Epoch: 006/010 | Batch 0150/0391 | Cost: 0.5734\n",
            "Epoch: 006/010 | Batch 0200/0391 | Cost: 0.6773\n",
            "Epoch: 006/010 | Batch 0250/0391 | Cost: 0.7121\n",
            "Epoch: 006/010 | Batch 0300/0391 | Cost: 0.8514\n",
            "Epoch: 006/010 | Batch 0350/0391 | Cost: 0.6753\n",
            "Epoch: 006/010 | Train: 79.104% |  Loss: 0.614\n",
            "Time elapsed: 4.96 min\n",
            "Epoch: 007/010 | Batch 0000/0391 | Cost: 0.5574\n",
            "Epoch: 007/010 | Batch 0050/0391 | Cost: 0.7103\n",
            "Epoch: 007/010 | Batch 0100/0391 | Cost: 0.7429\n",
            "Epoch: 007/010 | Batch 0150/0391 | Cost: 0.5408\n",
            "Epoch: 007/010 | Batch 0200/0391 | Cost: 0.5449\n",
            "Epoch: 007/010 | Batch 0250/0391 | Cost: 0.6159\n",
            "Epoch: 007/010 | Batch 0300/0391 | Cost: 0.7448\n",
            "Epoch: 007/010 | Batch 0350/0391 | Cost: 0.6857\n",
            "Epoch: 007/010 | Train: 82.954% |  Loss: 0.506\n",
            "Time elapsed: 5.82 min\n",
            "Epoch: 008/010 | Batch 0000/0391 | Cost: 0.5808\n",
            "Epoch: 008/010 | Batch 0050/0391 | Cost: 0.5048\n",
            "Epoch: 008/010 | Batch 0100/0391 | Cost: 0.5211\n",
            "Epoch: 008/010 | Batch 0150/0391 | Cost: 0.4525\n",
            "Epoch: 008/010 | Batch 0200/0391 | Cost: 0.6653\n",
            "Epoch: 008/010 | Batch 0250/0391 | Cost: 0.5637\n",
            "Epoch: 008/010 | Batch 0300/0391 | Cost: 0.6470\n",
            "Epoch: 008/010 | Batch 0350/0391 | Cost: 0.5367\n",
            "Epoch: 008/010 | Train: 85.900% |  Loss: 0.420\n",
            "Time elapsed: 6.68 min\n",
            "Epoch: 009/010 | Batch 0000/0391 | Cost: 0.4010\n",
            "Epoch: 009/010 | Batch 0050/0391 | Cost: 0.8205\n",
            "Epoch: 009/010 | Batch 0100/0391 | Cost: 0.3755\n",
            "Epoch: 009/010 | Batch 0150/0391 | Cost: 0.5558\n",
            "Epoch: 009/010 | Batch 0200/0391 | Cost: 0.3722\n",
            "Epoch: 009/010 | Batch 0250/0391 | Cost: 0.4545\n",
            "Epoch: 009/010 | Batch 0300/0391 | Cost: 0.5673\n",
            "Epoch: 009/010 | Batch 0350/0391 | Cost: 0.4247\n",
            "Epoch: 009/010 | Train: 87.030% |  Loss: 0.381\n",
            "Time elapsed: 7.53 min\n",
            "Epoch: 010/010 | Batch 0000/0391 | Cost: 0.2322\n",
            "Epoch: 010/010 | Batch 0050/0391 | Cost: 0.3475\n",
            "Epoch: 010/010 | Batch 0100/0391 | Cost: 0.3476\n",
            "Epoch: 010/010 | Batch 0150/0391 | Cost: 0.3241\n",
            "Epoch: 010/010 | Batch 0200/0391 | Cost: 0.4354\n",
            "Epoch: 010/010 | Batch 0250/0391 | Cost: 0.4164\n",
            "Epoch: 010/010 | Batch 0300/0391 | Cost: 0.5312\n",
            "Epoch: 010/010 | Batch 0350/0391 | Cost: 0.4359\n",
            "Epoch: 010/010 | Train: 87.448% |  Loss: 0.380\n",
            "Time elapsed: 8.39 min\n",
            "Total Training Time: 8.39 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLpUG8Iod79u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "719657f4-08b0-4660-cafe-52b654d3e296"
      },
      "source": [
        "with torch.set_grad_enabled(False): # save memory during inference\n",
        "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 75.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV84lrmReBSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}